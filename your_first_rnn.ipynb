{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your first Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üôå Welcome to RNNs! After using CNNs in the previous lesson to deal with images (spatial data), you are going to deal with time-related data (***temporal data***).\n",
    "\n",
    "üéØ Goals of this warm-up challenge:\n",
    "\n",
    "1. Understand what temporal data is\n",
    "2. Build your first Recurrent Neural Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Note on Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, you no longer need to use Google Colab. There will be **no performance gains** from using it, as today's machines are powerful enough to tackle this challenge ‚Äî especially if you're on a MacBook with an MX chip! üòâ\n",
    "\n",
    "Proceed with the challenge as you normally would with Jupyter Notebook (‚ùå Do not use Colab ‚ùå)\n",
    "\n",
    "Good luck! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) üìö The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Disclaimer: nothing to code by yourself in this section, read it carefully and run the cells. We want you to focus on the RNN and LSTM models, not some Pythonesque questions_ üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¢ Imagine that we have access to some data about employees in a company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è The dataset describes the evolution of the **employment status of 25 000 employees, year after year**: each sequence corresponds to 10 consecutive years, where each year describes a job situation, comprising 3 components\n",
    "- the salary,\n",
    "- the number of people under someone's responsibility,\n",
    "- the size of the company. \n",
    "\n",
    "üïµüèª To understand the dataset a bit better, let's look at the data of the first employee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "employee_0 = pd.DataFrame(X[0],\n",
    "                          columns=['salary',\n",
    "                                   'responsibility',\n",
    "                                   'company_size'])\n",
    "round(employee_0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ The goal in this challenge is to predict the montly salary on the 11th year for each of these 25,000 employees, based on the past observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, the first employee earns 6.499 k USD per month\n",
    "# during the 11th year at the company\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìà To help you get a better understanding about the evolution of the salaries, the number of people under their responsibility and the company size over the years, you can run the cell down below. Can you visually detect some correlations between these three variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "number_of_employees = len(X)\n",
    "\n",
    "### Choosing random employees\n",
    "##### As the employees are selected randomly, feel free to re-run this cell a few times !\n",
    "\n",
    "number_of_randomly_selected_employees = 5\n",
    "\n",
    "random_selection = np.random.randint(0, \n",
    "                                     number_of_employees,\n",
    "                                     number_of_randomly_selected_employees)\n",
    "\n",
    "\n",
    "### Plotting data for the selected employees\n",
    "\n",
    "plt.title('Salary')\n",
    "for r in random_selection:\n",
    "    plt.plot(X[r, :, 0],label=f\"Employee number {r}\",linestyle=\":\",marker=\"o\")\n",
    "    plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.title('# People responsibile for')\n",
    "for r in random_selection:\n",
    "    plt.plot(X[r, :, 1],label=f\"Employee number {r}\",linestyle=\":\",marker=\"o\")\n",
    "    plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Company sizes')\n",
    "for r in random_selection:\n",
    "    plt.plot(X[r, :, 2],label=f\"Employee number {r}\",linestyle=\":\",marker=\"o\")\n",
    "    plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üïµüèª **Data Exploration** üïµüèª Look at the distribution of:\n",
    "* all the salaries during the 10th year, \n",
    "* people under someone's responsibility, \n",
    "* and the company sizes \n",
    "\n",
    "to get a better understanding of the variability of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.title(\"Salaries on the 10th year\")\n",
    "sns.histplot(X[:, -1, 0].flatten()) # all the employees, last year, feature #0 = salaries\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"# of people under someone's responsibility\")\n",
    "sns.histplot(X[:, :, 1].flatten()) # all the employees, all the years, feature #1 = responsabilities\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Company size\")\n",
    "sns.histplot(X[:, :, 2].flatten()) # all the employees, all the years, feature #2 = company size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÇÔ∏è **Hold-out method** Let's split the dataset in a train and test set (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "# Notice that we are train_test_splitting the 25 000 employees!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) üíª A Simple RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§ó Now that you are familiar with this company's dataset, you will create your first Recurrent Neural Network. Let's start with a simple architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Write a model that has: \n",
    "- a ***Normalization*** layer adapted to the training set\n",
    "- a ***SimpleRNN*** layer with 20 *units* (don't forget that `tanh` is better suited as an activation function for a Recurrent Layer)\n",
    "- a ***Dense*** layer with 10 neurons\n",
    "- a ***Dense*** layer specific to your task (= to ***predict*** a salary)\n",
    "\n",
    "üë©üèª‚Äçüè´ <u>Remember</u>: You don't need to specify an `input_shape`: as soon as your Normalizer has been adapted to your train set, it has memorized the input shape!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question**: How many trainable parameters does your RNN have ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Try to recompute the number of parameters manually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><i>Answer</i></summary>\n",
    "\n",
    "\n",
    "- <u> Normalization Layer</u>: \n",
    "    - This layer has $\\color{red}{n_x = 3} $ features (salary, responsibility, company size) to normalize. Each of them requires to compute the <font color=blue>_mean_</font>  and the <font color=blue>_standard_deviation_</font>. So we have $\\color{red}{n_x = 3} \\times \\color{blue}{2} = 6$ non-trainable parameters. The 7th parameter is a bias initially set to 0.\n",
    "\n",
    "- <u> Recurrent Layer</u>: \n",
    "    - If $\\color{green}{n_h = 20} $ RNN units are applied in parallel to $\\color{red}{n_x = 3} $ features, then the Recurrent Layer has $\\color{green}{n_h}(\\color{green}{n_h} + \\color{red}{n_x} + 1) = \\color{green}{20} \\times (\\color{green}{20}+\\color{red}{3}+1) = \\color{green}{20} \\times 24 = 480$ parameters to train.\n",
    "    - Notice how this number is *independent* of the length of each sequence (here 10 days)\n",
    "    \n",
    "- <u> Dense Layer</u>: \n",
    "    - Starting with $\\color{green}{n_h = 20} $ RNN units and $1$ bias, using 10 neurons, the Dense Layer has $ (\\color{green}{20}+1) \\times 10 = 21 \\times 10 = 210$ parameters\n",
    "    \n",
    "- <u> Predictive Dense Layer</u>: \n",
    "    - Starting with $10$ neurons and $1$ bias, using 1 neuron to predict the 11th salary, the Predictive Dense Layer has $ (10+1) \\times 1 = 11 \\times 1 = 11$ parameters\n",
    "    \n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Compile your model. For RNN, we recommend you to use the ***rmsprop*** optimizer (instead of *adam*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** ‚ùì \n",
    "\n",
    "* Train your model on your training dataset:\n",
    "    * use a Validation Split of 20%\n",
    "    * and an Early Stopping Criterion with patience $= 5 $\n",
    "* Evaluate your performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) üíª Baseline comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ‚ùóÔ∏è **Important reminder** ‚ùóÔ∏è \n",
    ">  \n",
    "> ***Always remember to compare your Deep Learning models, and more generally any Machine Learning model, to a baseline model.***\n",
    "\n",
    "üßëüèª‚Äçüè´ Remember that our goal is to predict the salary of the employees for the 11th year. It is a ***Regression task***. What baseline could we build? \n",
    "1. In the case of a traditional regression model, a baseline prediction for `y_test` is  to **predict the average of `y_train`**... but this option could be irrelevant for time-related series. Theoretically, someone's salary is supposed to increase over the years!\n",
    "2. An alternative baseline prediction for a regression task is to **predict the last seen value**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** ‚ùì \n",
    "* Compute the Mean Absolute Error of a baseline model that predicts that the salary remains constant between the 10-th and 11-th year\n",
    "* Compare this baseline model to your RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ If you are stuck with this question, try `(4) LSTM` and come back to this afterwards.\n",
    "\n",
    "üßëüèª‚Äçüè´ Ask a TA if needed. Look at the answer only if you already tried to answer these questions unsuccessfully.\n",
    "\n",
    "<details>\n",
    "    <summary><i>Answer</i></summary>\n",
    "\n",
    "\n",
    "```python\n",
    "def constant_prediction(X, y):\n",
    "    errors = []\n",
    "    for xx, yy in zip(X, y):\n",
    "        last_salary = xx[-1][0]        # Using the 10th salary to predict the 11th salary\n",
    "        errors.append(yy - last_salary)\n",
    "        \n",
    "    return errors    \n",
    "```\n",
    "    \n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üòÅ You should notice that your RNN performs a bit better than a baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) üíª LSTM: Long-Short Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** ‚ùì \n",
    "\n",
    "* Write the exact same model, but with a `LSTM` layer instead of a `SimpleRNN` layer\n",
    "* Evaluate your performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí™ The LSTM should perform a bit better than the SimpleRNN with a lower MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! You know how to train a RNN on sequential data.\n",
    " \n",
    "\n",
    "üíæ Do not forget to git add/commit/push your notebook...\n",
    "\n",
    "üöÄ ... and move to the next challenge!\n",
    "\n",
    "---\n",
    "\n",
    "<u>Note</u>: The sequences you worked with are totally fake. In case, you need to train and reproduce similar data, you can find below the functions that have been used to simulate such a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ† (Utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(number):\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(number):\n",
    "        x_i, y_i = create_individual_sequence(10)\n",
    "        X.append(x_i)\n",
    "        y.append(y_i)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "            \n",
    "def create_individual_sequence(length):\n",
    "    company_sizes = []\n",
    "    nb_persons = []\n",
    "    salaries = []\n",
    "    \n",
    "    \n",
    "    # Education level\n",
    "    educ_level = [max(0, int(np.random.normal(10, 2)))]*length\n",
    "    \n",
    "    # Company size\n",
    "    current_size = int(1 + np.random.beta(.4, 4)*500)\n",
    "    for i in range(length):\n",
    "        if not np.random.randint(4): # Change 1 out of 3 possibilities \n",
    "            current_size = int(max(1, np.random.normal(current_size, 50)))\n",
    "        company_sizes.append(current_size)\n",
    "    \n",
    "    # Number of persons\n",
    "    nb_iter = np.random.beta(.15, 4)*300\n",
    "    for i in range(length):\n",
    "        if not np.random.randint(2): # Change 1 out of 2 possibilities\n",
    "            R_1 = np.random.beta(0.5, 8)*3\n",
    "            nb_iter = nb_iter + max(-2, R_1*company_sizes[i] + np.random.randint(-2, 2))\n",
    "            nb_iter = max(0, nb_iter)\n",
    "            nb_iter = int(min(company_sizes[i]-1, nb_iter))\n",
    "        nb_persons.append(nb_iter)\n",
    "        \n",
    "    \n",
    "    # Salary\n",
    "    salary_iter = max(800, int(np.random.normal(1200, 300)+ 0.05*company_sizes[0] +  np.random.normal(40, 400)))\n",
    "    salaries.append(salary_iter)\n",
    "    for i in range(1, length + 1):\n",
    "        R_1 = np.random.normal(100, 50)\n",
    "        change_person = nb_persons[i-1] - nb_persons[i-2]\n",
    "        change_company = max(0, company_sizes[i-1] - company_sizes[i-2])\n",
    "        salary_iter = salary_iter + 0.05*change_company + change_person*R_1 + np.random.normal(100, 50)\n",
    "        salary_iter = max(int(salary_iter), 500)\n",
    "        \n",
    "        salaries.append(salary_iter)\n",
    "\n",
    "    y = salaries[-1]/1000\n",
    "    salaries = [_/1000 for _ in salaries[:-1]]\n",
    "    \n",
    "    return np.array([salaries, nb_persons, company_sizes]).T, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = create_sequences(25000)\n",
    "\n",
    "#np.save('X', X.astype(np.float32))\n",
    "#np.save('y', y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
